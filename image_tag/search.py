# -*- coding: utf-8 -*-
"""search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5rveQ8PTzxRAytBcC-ryAoSxr_H5qsS
"""

from pathlib import Path
import pickle
import faiss
import numpy as np
from PIL import Image
import torch
import os
import google.generativeai as genai
from transformers import CLIPProcessor, CLIPModel

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

# ----------------------  Core Search Engine  ----------------------
class SearchEngine:
    def __init__(self, base_dir=None, use_gemini=False, gemini_key=None):
        # Base path for index / metadata
        if base_dir:
            self.base = Path(base_dir)
        elif "__file__" in globals():
            self.base = Path(__file__).resolve().parent
        else:
            self.base = Path(os.getcwd())

        # Load FAISS + metadata
        self.index = faiss.read_index(str(self.base / "image_index.faiss"))
        with open(self.base / "metadata_with_paths.pkl", "rb") as f:
            self.metadata = pickle.load(f)

        # CLIP
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.clip_model = CLIPModel.from_pretrained(
            "openai/clip-vit-base-patch32"
        ).to(self.device)
        self.clip_proc = CLIPProcessor.from_pretrained(
            "openai/clip-vit-base-patch32", 
            use_fast=True
        )

        # Gemini
        key = gemini_key or os.environ.get("GOOGLE_API_KEY")
        self.use_gemini = bool(use_gemini and key)
        self.gemini_key = key

        if self.use_gemini:
            if not GEMINI_AVAILABLE or genai is None:
                raise ImportError("google-generativeai library not installed.")
            genai.configure(api_key=key)
            print("[INFO] Gemini API configured successfully.")

    # ----- embeddings -----
    def embed_text(self, text: str):
        inp = self.clip_proc(text=[text], return_tensors="pt", padding=True).to(self.device)
        with torch.no_grad():
            return self.clip_model.get_text_features(**inp).cpu().numpy().astype("float32")

    def embed_image(self, path: str):
        img = Image.open(path).convert("RGB")
        inp = self.clip_proc(images=img, return_tensors="pt").to(self.device)
        with torch.no_grad():
            return self.clip_model.get_image_features(**inp).cpu().numpy().astype("float32")

    def _rewrite(self, text):
        if not self.use_gemini:
            return text
        prompt = (
            "Rewrite this fashion search query to be concise and descriptive, "
            "focusing on clothing style, color, weather, or occasion:\n\n"
            f"{text}"
        )
        model = genai.GenerativeModel("gemini-1.5-flash")
        return model.generate_content(prompt).text.strip()

    # ----- main search -----
    def search(self, query_text=None, query_image=None, k=5):
        if not (query_text or query_image):
            raise ValueError("Provide query_text or query_image")

        text = self._rewrite(query_text) if query_text else None

        vecs = []
        if text:
            vecs.append(self.embed_text(text))
        if query_image:
            vecs.append(self.embed_image(query_image))

        query_emb = np.mean(vecs, axis=0)
        D, I = self.index.search(query_emb, k)
        return [self.metadata[i]["image_path"] for i in I[0]]

# ----------------------  FastAPI wrapper  ----------------------

from fastapi import FastAPI, Query, UploadFile, File
from fastapi.responses import JSONResponse
import tempfile, shutil

app = FastAPI(title="Vibe Search API")
_engine: SearchEngine = None   # lazy init

def get_engine():
    global _engine
    if _engine is None:
        _engine = SearchEngine(use_gemini=False)  # set True + key for Gemini
    return _engine

@app.get("/search")
async def search_endpoint(q: str = Query(None, description="Text query"),
                          k: int = Query(5, description="Number of results")):
    engine = get_engine()
    return JSONResponse({"results": engine.search(query_text=q, k=k)})

